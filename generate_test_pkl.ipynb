{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "def preproc_frcnn(img):\n",
    "    \"\"\" follow the processing steps of fasterRCNN\n",
    "    \"\"\"\n",
    "    img = np.asarray(img[:,:,::-1], dtype=np.float32)\n",
    "    PIXEL_MEANS = np.array([[[102.9801, 115.9465, 122.7717]]])  #cfg  pixel_means\n",
    "    img -= PIXEL_MEANS\n",
    "    \n",
    "    return torch.tensor(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pickle of random all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_test_pkl(filename, ext, D_SIZE, BASE_DIR, output_test_pkl_path):\n",
    "    # read filename\n",
    "    with open(filename) as file:\n",
    "        lines = file.readlines()\n",
    "        lines = [line.rstrip() for line in lines]\n",
    "\n",
    "    # add ext\n",
    "    file_names =[s +ext for s in lines]\n",
    "    print(len(file_names))\n",
    "\n",
    "    # write to pkl\n",
    "    imgs_raw = [cv2.imread(os.path.join(BASE_DIR, fn))for fn in file_names]\n",
    "    imgs_resize = [cv2.resize(img, dsize=D_SIZE, interpolation=cv2.INTER_CUBIC) for img in imgs_raw]\n",
    "    imgs = [preproc_frcnn(img).unsqueeze(0).permute(0, 3, 1, 2) for img in imgs_resize]\n",
    "    with open(output_test_pkl_path,'wb') as f:\n",
    "        pickle.dump(imgs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  BDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* random pick 500 as test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "BDD_filename = 'data/BDD100K/ImageSets/Main/val.txt'\n",
    "with open(BDD_filename) as f:\n",
    "    alist = [line.rstrip() for line in f]\n",
    "alist = sample(alist,1000)\n",
    "\n",
    "with open('data/BDD100K/ImageSets/Main/val_1000.txt', 'w') as f:\n",
    "    for item in alist:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "filename = 'data/BDD100K/ImageSets/Main/val_1000.txt'  #3325\n",
    "ext='.jpg'\n",
    "D_SIZE=(480,640)\n",
    "BASE_DIR = 'data/BDD100K/JPEGImages'\n",
    "output_test_pkl_path = 'data/pickle/BDD_val_1000.pkl'\n",
    "generate_test_pkl(filename, ext, D_SIZE, BASE_DIR, output_test_pkl_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MI3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1070\n"
     ]
    }
   ],
   "source": [
    "filename = '/home/superorange5/MI3_dataset/MI3_dataset/ImageSets/Main/val.txt.random'  #3325\n",
    "ext='.jpg'\n",
    "D_SIZE=(480,640)\n",
    "BASE_DIR = '/home/superorange5/MI3_dataset/MI3_dataset/JPEGImages'\n",
    "output_test_pkl_path = 'data/pickle/MI3_val_1070.pkl'\n",
    "generate_test_pkl(filename, ext, D_SIZE, BASE_DIR, output_test_pkl_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 640, 480])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs[1000].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pickle of each target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pkl_by_scene(scene):\n",
    "    BASE_DIR = '/home/superorange5/MI3_dataset/MI3_dataset_bydataset/'+scene\n",
    "\n",
    "    file_names = [f for f in os.listdir(BASE_DIR) if '.jpg' in f]\n",
    "    imgs_raw = [imread(os.path.join(BASE_DIR, fn)) for fn in file_names]\n",
    "    imgs = [preproc_frcnn(img).unsqueeze(0).permute(0, 3, 1, 2) for img in imgs_raw]\n",
    "    with open('data/pickle/MI3_test_'+scene+'.pkl','wb') as f:\n",
    "        pickle.dump(imgs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_list = ['Pathway','Doorway','Room','Bus'] #Staircase\n",
    "for scene in scene_list:\n",
    "    generate_pkl_by_scene(scene)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## verify by readking pickle back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = 'Pathway'\n",
    "with open('data/pickle/MI3_test_'+scene+'.pkl', 'rb') as handle:\n",
    "    test_images = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/pickle/MI3_test_3325.pkl', 'rb') as handle:\n",
    "    test_images = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 640, 480])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images[1000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rcnn_intermediate(model, x):\n",
    "    \"\"\" Get intermediate results of specifc model.\n",
    "        Note: This is NOT a generalized function for all torch models,\n",
    "              due to the different arch. of models.\n",
    "    \"\"\"\n",
    "    from torch.nn import MaxPool2d, AdaptiveAvgPool2d\n",
    "    \n",
    "    # forward the features layers of VGG.\n",
    "    for l in list(model.RCNN_base.modules())[0]:\n",
    "        x = l(x)\n",
    "        \n",
    "    x = MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)(x)   \n",
    "    \n",
    "    x = AdaptiveAvgPool2d(output_size=(7, 7))(x)\n",
    "    \n",
    "    # flatten for FC layers.\n",
    "    x = x.view(x.shape[0], -1)\n",
    "    \n",
    "#     # go through FC layers.\n",
    "#     for l in list(model.RCNN_top.modules())[0]:\n",
    "#         x = l(x)\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vgg16(\n",
       "  (RCNN_rpn): _RPN(\n",
       "    (RPN_Conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (RPN_cls_score): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (RPN_bbox_pred): Conv2d(512, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (RPN_proposal): _ProposalLayer()\n",
       "    (RPN_anchor_target): _AnchorTargetLayer()\n",
       "  )\n",
       "  (RCNN_proposal_target): _ProposalTargetLayer()\n",
       "  (RCNN_roi_pool): ROIPool(output_size=(7, 7), spatial_scale=0.0625)\n",
       "  (RCNN_roi_align): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0)\n",
       "  (RCNN_base): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace)\n",
       "  )\n",
       "  (RCNN_top): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace)\n",
       "    (5): Dropout(p=0.5)\n",
       "  )\n",
       "  (RCNN_cls_score): Linear(in_features=4096, out_features=2, bias=True)\n",
       "  (RCNN_bbox_pred): Linear(in_features=4096, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import _init_paths\n",
    "\n",
    "from model.faster_rcnn.vgg16 import vgg16\n",
    "\n",
    "model_campus  = torch.load('models/vgg16/MI3/baseline_noDoorway/faster_rcnn_1_20_521.pth')\n",
    "\n",
    "MI3_classes = np.asarray(['__background__','person'])\n",
    "\n",
    "fasterRCNN = vgg16(MI3_classes, pretrained=False, class_agnostic='class_agnostic')\n",
    "fasterRCNN.create_architecture()\n",
    "fasterRCNN.eval()\n",
    "fasterRCNN.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "\n",
    "\n",
    "batch_sz = 24\n",
    "n_batch = len(test_images)//batch_sz\n",
    "res_batch = len(test_images)%batch_sz    \n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(n_batch):\n",
    "        in_batch = torch.cat(test_images[i*batch_sz:(i+1)*batch_sz]).to('cuda')\n",
    "        x = rcnn_intermediate(fasterRCNN, in_batch)\n",
    "        in_batch.to('cpu')\n",
    "        outputs.append(x)\n",
    "\n",
    "    # last incomplete batch.\n",
    "    in_batch = torch.cat(test_images[-res_batch:]).to('cuda')\n",
    "    x = rcnn_intermediate(fasterRCNN, in_batch)\n",
    "    in_batch.to('cpu')\n",
    "    outputs.append(x)\n",
    "\n",
    "outputs = torch.cat(outputs)\n",
    "X = outputs.to('cpu').numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.7695785 , 3.1710246 , 2.7350667 , ..., 0.        , 0.        ,\n",
       "        0.05313465],\n",
       "       [4.9088845 , 3.2225666 , 3.1833305 , ..., 0.        , 0.        ,\n",
       "        0.04309072],\n",
       "       [4.968571  , 3.1741734 , 3.1645584 , ..., 0.        , 0.        ,\n",
       "        0.04143884],\n",
       "       ...,\n",
       "       [5.144362  , 4.92007   , 2.9027584 , ..., 0.        , 0.        ,\n",
       "        0.13285919],\n",
       "       [4.648894  , 3.2865324 , 3.000243  , ..., 0.        , 0.        ,\n",
       "        0.05819702],\n",
       "       [4.5997963 , 3.6297185 , 3.0870798 , ..., 0.        , 0.        ,\n",
       "        0.23383969]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fasterRCNN",
   "language": "python",
   "name": "fasterrcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
