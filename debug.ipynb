{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea1bc524",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import _init_paths\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from model.faster_rcnn.vgg16 import vgg16\n",
    "from model.utils.config import cfg, cfg_from_list\n",
    "#from datasets.factory import get_imdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f90e6193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17952\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17d02569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': array([[712, 143, 810, 307]], dtype=uint16),\n",
       " 'gt_classes': array([2], dtype=int32),\n",
       " 'gt_ishard': array([0], dtype=int32),\n",
       " 'gt_overlaps': <1x3 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 1 stored elements in Compressed Sparse Row format>,\n",
       " 'flipped': False,\n",
       " 'seg_areas': array([16335.], dtype=float32),\n",
       " 'img_id': 0,\n",
       " 'image': '/home/superorange5/Research/FedWCD/data/KITTI/JPEGImages/000000.png',\n",
       " 'width': 1224,\n",
       " 'height': 370,\n",
       " 'max_classes': array([2]),\n",
       " 'max_overlaps': array([1.], dtype=float32)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6084de0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for datainfo in data:\n",
    "    wh_pair =[(1242,375),(1224,370),(1238,374),(1241,376)]\n",
    "\n",
    "    width = datainfo['width']\n",
    "    height = datainfo['height']\n",
    "    temp = (width,height)\n",
    "    if (temp not in wh_pair):\n",
    "        print(datainfo['image'])\n",
    "        print (width)\n",
    "        print (height)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff15dad8",
   "metadata": {},
   "source": [
    "# BDD converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "06192793",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "json_path = '/work/superorange5/bdd100k/labels/bdd100k_labels_images_val.json'\n",
    "with open(json_path) as f:\n",
    "    j = f.read()\n",
    "    data = json.loads(j)\n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "#     print(datum['name'])\n",
    "    \n",
    "# for datum in tqdm(data):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ea32e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8ca2d8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7247d5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open(\"val.txt\", \"w\")\n",
    "\n",
    "for datum in data:\n",
    "    if(datum['attributes']['timeofday'] =='daytime'):\n",
    "        fp.write(datum['name'].replace('.jpg','')+\"\\n\" )\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0d6e761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['name', 'attributes', 'timestamp', 'labels'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28d90bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for datum in data:\n",
    "   \n",
    "    # bounding box\n",
    "    for label in datum['labels']:\n",
    "        classes = label['category']\n",
    "        if classes =='motor':\n",
    "            print(\"motorcycle\")\n",
    "        elif classes =='bike':\n",
    "            print(\"bicycle\")\n",
    "        elif classes =='traffic light':\n",
    "            print(\"skip\")\n",
    "        elif classes =='traffic sign':\n",
    "            print(\"skip\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "befbae3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0000f77c-6257be58.jpg'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['name']   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d740196a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'daytime'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['attributes']['timeofday']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50789287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'traffic light'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['labels'][0]['category']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6ae482",
   "metadata": {},
   "source": [
    "## read XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2fc46618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "# assign directory\n",
    "directory = 'data/KITTI/Annotations/'\n",
    "\n",
    "count=0\n",
    "    # check exist car or not\n",
    "for filename in os.listdir(directory):\n",
    "    #print(filename)\n",
    "    \n",
    "    tree = ET.parse(os.path.join(directory,filename))\n",
    "    root = tree.getroot()\n",
    "\n",
    "    objs = tree.findall('object')\n",
    "\n",
    "\n",
    "            # Load object bounding boxes into a data frame.\n",
    "    num_objs =0\n",
    "    for ix, obj in enumerate(objs):\n",
    "        bbox = obj.find('bndbox')\n",
    "\n",
    "#         x1 = max(float(bbox.find('xmin').text), 0)\n",
    "#         y1 = max(float(bbox.find('ymin').text), 0)\n",
    "#         x2 = max(float(bbox.find('xmax').text), 0)\n",
    "#         y2 = max(float(bbox.find('ymax').text), 0)\n",
    "\n",
    "\n",
    "        class_name = obj.find('name').text.lower().strip()\n",
    "        if class_name=='car':            \n",
    "            num_objs+=1\n",
    "        #print(class_name)\n",
    "    #print(num_objs)\n",
    "    if (num_objs)==0:\n",
    "        #print(filename)\n",
    "        count+=1\n",
    "print(count)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067fcd05",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "1f004f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "3b6ab54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"models/vgg16/multi_ck/faster_rcnn_1_20_17897.pth\"\n",
    "model  = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "08facdfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vgg16(\n",
       "  (RCNN_rpn): _RPN(\n",
       "    (RPN_Conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (RPN_cls_score): Conv2d(512, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (RPN_bbox_pred): Conv2d(512, 36, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (RPN_proposal): _ProposalLayer()\n",
       "    (RPN_anchor_target): _AnchorTargetLayer()\n",
       "  )\n",
       "  (RCNN_proposal_target): _ProposalTargetLayer()\n",
       "  (RCNN_roi_pool): ROIPool(output_size=(7, 7), spatial_scale=0.0625)\n",
       "  (RCNN_roi_align): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0)\n",
       "  (RCNN_base): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace)\n",
       "  )\n",
       "  (RCNN_top): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace)\n",
       "    (5): Dropout(p=0.5)\n",
       "  )\n",
       "  (RCNN_cls_score): Linear(in_features=4096, out_features=9, bias=True)\n",
       "  (RCNN_bbox_pred): Linear(in_features=4096, out_features=36, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = np.asarray(['__background__', 'car', 'person', 'bus', 'bicycle', 'motorcycle','rider', 'train', 'truck'])\n",
    "set_cfgs = ['ANCHOR_SCALES', '[8, 16, 32]', 'ANCHOR_RATIOS', '[0.5,1,2]', 'MAX_NUM_GT_BOXES', '20'] \n",
    "\n",
    "cfg_from_list(set_cfgs)\n",
    "fasterRCNN = vgg16(classes, pretrained=False, class_agnostic=False)\n",
    "fasterRCNN.create_architecture()\n",
    "fasterRCNN.eval()\n",
    "fasterRCNN.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "0f65bd18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasterRCNN.load_state_dict(model['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c423a9",
   "metadata": {},
   "source": [
    "## check xml class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e491a69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def read_annotation(x):\n",
    "    filename = os.path.join('data/KITTI','xml',x +'.xml')\n",
    "    #print(filename)\n",
    "    tree = ET.parse(filename)\n",
    "    objs = tree.findall('object')\n",
    "\n",
    "    for ix, obj in enumerate(objs):\n",
    "        bbox = obj.find('bndbox')\n",
    "        cls=obj.find('name').text.lower().strip()\n",
    "        if(cls=='tram'):\n",
    "            print(filename)\n",
    "        if('motorbike' == cls):\n",
    "            continue\n",
    "        #cls = _class_to_ind[obj.find('name').text.lower().strip()]\n",
    "    return filename\n",
    "\n",
    "#image_set_file = os.path.join('data/SIM10K/VOC2012', 'ImageSets', 'Main',  'trainval10k.txt')\n",
    "image_set_file = os.path.join('data/KITTI', 'ImageSets', 'Main',  'train.txt')\n",
    "classes = ('__background__', 'car', 'person', 'bus', 'bicycle', 'motorcycle','rider', 'train', 'truck')\n",
    "num_classes = len(classes)\n",
    "_class_to_ind = dict(zip(classes, range(num_classes)))\n",
    "with open(image_set_file) as f:\n",
    "    for x in f.readlines():\n",
    "        x = x.rstrip(\"\\n\")\n",
    "        read_annotation(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3349b0",
   "metadata": {},
   "source": [
    "## voc_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41ace34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "data_cache_path = 'data/cache'\n",
    "pkl_file = os.path.join(data_cache_path, 'kitti_train' + '_gt_roidb.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f268b776",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pkl_file, 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e8d16617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': array([[0, 0, 0, 0],\n",
       "        [0, 0, 0, 0]], dtype=uint16),\n",
       " 'gt_classes': array([0, 0], dtype=int32),\n",
       " 'gt_ishard': array([0, 0], dtype=int32),\n",
       " 'gt_overlaps': <2x2 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 0 stored elements in Compressed Sparse Row format>,\n",
       " 'flipped': False,\n",
       " 'seg_areas': array([0., 0.], dtype=float32),\n",
       " 'img_id': 3180,\n",
       " 'image': '/home/superorange5/Research/FedWCD/data/KITTI/JPEGImages/003955.png',\n",
       " 'width': 1242,\n",
       " 'height': 375,\n",
       " 'max_classes': array([0, 0]),\n",
       " 'max_overlaps': array([0., 0.], dtype=float32)}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[3180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffa3ce73",
   "metadata": {},
   "outputs": [],
   "source": [
    "devkit_path = '/work/superorange5/bdd100k'\n",
    "cachedir = os.path.join(devkit_path, 'annotations_cache')\n",
    "image_set='val'\n",
    "imagesetfile = os.path.join(devkit_path,  'ImageSets',\n",
    "            'Main',   image_set + '.txt')\n",
    "cachefile = os.path.join(cachedir, '%s_annots.pkl' % imagesetfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdc105a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "annopath = os.path.join(devkit_path, 'Annotations', '{:s}.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "307b1187",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(imagesetfile, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "imagenames = [x.strip() for x in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ab0cb42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/work/superorange5/bdd100k/ImageSets/Main/val.txt_annots.pkl'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cachefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56a8fac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imagenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3179d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.datasets.voc_eval as voc_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198789a6",
   "metadata": {},
   "source": [
    "## generate gt pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e17cfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving cached annotations to /work/superorange5/bdd100k/ImageSets/Main/val.txt_annots.pkl\n"
     ]
    }
   ],
   "source": [
    "recs = {}\n",
    "#for i in range(1000):\n",
    "#    imagename = imagenames[i]\n",
    "for i, imagename in enumerate(imagenames):\n",
    "    recs[imagename] = voc_eval.parse_rec(annopath.format(imagename))\n",
    "    if i % 100 == 0:\n",
    "        print('Reading annotation for {:d}/{:d}'.format(\n",
    "          i + 1, len(imagenames)))\n",
    "print('Saving cached annotations to {:s}'.format(cachefile))\n",
    "with open(cachefile, 'wb') as f:\n",
    "        pickle.dump(recs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f9b7503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'traffic light', 'truncated': 0, 'bbox': [449, 123, 471, 146]},\n",
       " {'name': 'traffic sign', 'truncated': 0, 'bbox': [638, 206, 653, 231]},\n",
       " {'name': 'traffic sign', 'truncated': 0, 'bbox': [199, 179, 231, 212]},\n",
       " {'name': 'car', 'truncated': 0, 'bbox': [439, 222, 698, 430]},\n",
       " {'name': 'car', 'truncated': 1, 'bbox': [1136, 200, 1278, 333]},\n",
       " {'name': 'motor', 'truncated': 1, 'bbox': [1204, 232, 1277, 330]}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs['b1ca8418-84a133a0']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cbe3c7",
   "metadata": {},
   "source": [
    "## extract gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5c76daca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classname = 'car' \n",
    "class_recs = {}\n",
    "npos = 0\n",
    "ovthresh=0.5\n",
    "for imagename in imagenames:\n",
    "    R = [obj for obj in recs[imagename] if obj['name'] == classname]\n",
    "    bbox = np.array([x['bbox'] for x in R])\n",
    "    #difficult = np.array([x['difficult'] for x in R]).astype(np.bool)\n",
    "    det = [False] * len(R)\n",
    "    npos = npos +  len(R) #sum(~difficult)\n",
    "    class_recs[imagename] = {'bbox': bbox,\n",
    "     #                        'difficult': difficult,\n",
    "                             'det': det}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f156e45",
   "metadata": {},
   "source": [
    "## read dets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2f88473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "detfile = os.path.join(devkit_path,'results/Main/comp4_det_val_'+classname+'.txt')\n",
    "with open(detfile, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "splitlines = [x.strip().split(' ') for x in lines]\n",
    "image_ids = [x[0] for x in splitlines]\n",
    "confidence = np.array([float(x[1]) for x in splitlines])\n",
    "BB = np.array([[float(z) for z in x[2:]] for x in splitlines])\n",
    "\n",
    "nd = len(image_ids)\n",
    "tp = np.zeros(nd)\n",
    "fp = np.zeros(nd)\n",
    "\n",
    "if BB.shape[0] > 0:\n",
    "    # sort by confidence\n",
    "    sorted_ind = np.argsort(-confidence)\n",
    "    sorted_scores = np.sort(-confidence)\n",
    "    BB = BB[sorted_ind, :]\n",
    "    image_ids = [image_ids[x] for x in sorted_ind]\n",
    "\n",
    "    # go down dets and mark TPs and FPs\n",
    "    for d in range(nd):\n",
    "        R = class_recs[image_ids[d]]\n",
    "        bb = BB[d, :].astype(float)\n",
    "        ovmax = -np.inf\n",
    "        BBGT = R['bbox'].astype(float)\n",
    "\n",
    "        if BBGT.size > 0:\n",
    "        # compute overlaps\n",
    "        # intersection\n",
    "            ixmin = np.maximum(BBGT[:, 0], bb[0])\n",
    "            iymin = np.maximum(BBGT[:, 1], bb[1])\n",
    "            ixmax = np.minimum(BBGT[:, 2], bb[2])\n",
    "            iymax = np.minimum(BBGT[:, 3], bb[3])\n",
    "            iw = np.maximum(ixmax - ixmin + 1., 0.)\n",
    "            ih = np.maximum(iymax - iymin + 1., 0.)\n",
    "            inters = iw * ih\n",
    "\n",
    "            # union\n",
    "            uni = ((bb[2] - bb[0] + 1.) * (bb[3] - bb[1] + 1.) +\n",
    "                   (BBGT[:, 2] - BBGT[:, 0] + 1.) *\n",
    "                   (BBGT[:, 3] - BBGT[:, 1] + 1.) - inters)\n",
    "\n",
    "            overlaps = inters / uni\n",
    "            ovmax = np.max(overlaps)\n",
    "            jmax = np.argmax(overlaps)\n",
    "\n",
    "        if ovmax > ovthresh:\n",
    "        #if not R['difficult'][jmax]:\n",
    "            if not R['det'][jmax]:\n",
    "                tp[d] = 1.\n",
    "                R['det'][jmax] = 1\n",
    "            else:\n",
    "                fp[d] = 1.\n",
    "        else:\n",
    "            fp[d] = 1.\n",
    "\n",
    "  # compute precision recall\n",
    "fp = np.cumsum(fp)\n",
    "tp = np.cumsum(tp)\n",
    "rec = tp / float(npos)\n",
    "  # avoid divide by zero in case the first detection matches a difficult\n",
    "  # ground truth\n",
    "prec = tp / np.maximum(tp + fp, np.finfo(np.float64).eps)\n",
    "ap = voc_eval.voc_ap(rec, prec, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "44686ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2416113877975409"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7fde856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(cachefile):\n",
    "    # load annotations\n",
    "    recs = {}\n",
    "    for i, imagename in enumerate(imagenames):\n",
    "      recs[imagename] = parse_rec(annopath.format(imagename))\n",
    "      if i % 10 == 0:\n",
    "        print('Reading annotation for {:d}/{:d}'.format(\n",
    "          i + 1, len(imagenames)))\n",
    "    # save\n",
    "    print('Saving cached annotations to {:s}'.format(cachefile))\n",
    "    with open(cachefile, 'wb') as f:\n",
    "      pickle.dump(recs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06253902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': array([[1001,  282, 1041,  327],\n",
       "        [ 215,  172,  275,  230],\n",
       "        [ 797,  313,  830,  342],\n",
       "        [ 653,  303,  685,  316],\n",
       "        [ 707,  312,  716,  328],\n",
       "        [ 626,  296,  636,  317],\n",
       "        [ 317,  289,  329,  307],\n",
       "        [ 271,  288,  309,  302],\n",
       "        [ 221,  301,  232,  312],\n",
       "        [ 206,  338,  282,  388],\n",
       "        [  47,  344,  130,  401],\n",
       "        [ 247,  344,  347,  396],\n",
       "        [   0,  337,   52,  403],\n",
       "        [ 650,  354,  664,  382],\n",
       "        [ 649,  367,  664,  388],\n",
       "        [ 712,  337,  726,  353],\n",
       "        [ 684,  357,  721,  393],\n",
       "        [ 706,  364,  734,  391],\n",
       "        [ 727,  366,  761,  401],\n",
       "        [ 749,  362,  809,  409],\n",
       "        [ 787,  358,  906,  425],\n",
       "        [ 880,  376,  960,  452],\n",
       "        [ 936,  336, 1212,  484],\n",
       "        [1204,  416, 1279,  530],\n",
       "        [ 603,  341,  610,  353],\n",
       "        [ 591,  328,  598,  342],\n",
       "        [ 529,  332,  537,  342],\n",
       "        [ 552,  356,  565,  368],\n",
       "        [ 574,  352,  586,  369],\n",
       "        [ 581,  357,  598,  378],\n",
       "        [ 596,  352,  636,  386],\n",
       "        [ 518,  356,  535,  368],\n",
       "        [ 502,  357,  518,  371],\n",
       "        [ 453,  353,  479,  373]], dtype=uint16),\n",
       " 'gt_classes': array([9, 9, 9, 9, 8, 8, 8, 9, 9, 1, 1, 1, 1, 3, 7, 8, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1], dtype=int32),\n",
       " 'gt_ishard': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " 'gt_overlaps': <34x11 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 34 stored elements in Compressed Sparse Row format>,\n",
       " 'flipped': False,\n",
       " 'seg_areas': array([ 1886.,  3599.,  1020.,   462.,   170.,   242.,   247.,   585.,\n",
       "          144.,  3927.,  4872.,  5353.,  3551.,   435.,   352.,   255.,\n",
       "         1406.,   812.,  1260.,  2928.,  8160.,  6237., 41273.,  8740.,\n",
       "          104.,   120.,    99.,   182.,   234.,   396.,  1435.,   234.,\n",
       "          255.,   567.], dtype=float32),\n",
       " 'img_id': 0,\n",
       " 'image': '/home/superorange5/Research/FedWCD/data/BDD100K/JPEGImages/b1c66a42-6f7d68ca.jpg',\n",
       " 'width': 1280,\n",
       " 'height': 720,\n",
       " 'max_classes': array([9, 9, 9, 9, 8, 8, 8, 9, 9, 1, 1, 1, 1, 3, 7, 8, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "  cachefile = os.path.join(cachedir, '%s_annots.pkl' % imagesetfile)\n",
    "  # read list of images\n",
    "  with open(imagesetfile, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "  imagenames = [x.strip() for x in lines]\n",
    "\n",
    "  if not os.path.isfile(cachefile):\n",
    "    # load annotations\n",
    "    recs = {}\n",
    "    for i, imagename in enumerate(imagenames):\n",
    "      recs[imagename] = parse_rec(annopath.format(imagename))\n",
    "      if i % 100 == 0:\n",
    "        print('Reading annotation for {:d}/{:d}'.format(\n",
    "          i + 1, len(imagenames)))\n",
    "    # save\n",
    "    print('Saving cached annotations to {:s}'.format(cachefile))\n",
    "    with open(cachefile, 'wb') as f:\n",
    "      pickle.dump(recs, f)\n",
    "  else:\n",
    "    # load\n",
    "    with open(cachefile, 'rb') as f:\n",
    "      try:\n",
    "        recs = pickle.load(f)\n",
    "      except:\n",
    "        recs = pickle.load(f, encoding='bytes')\n",
    "\n",
    "  # extract gt objects for this class\n",
    "  class_recs = {}\n",
    "  npos = 0\n",
    "  for imagename in imagenames:\n",
    "    R = [obj for obj in recs[imagename] if obj['name'] == classname]\n",
    "    bbox = np.array([x['bbox'] for x in R])\n",
    "    #difficult = np.array([x['difficult'] for x in R]).astype(np.bool)\n",
    "    det = [False] * len(R)\n",
    "    #npos = npos + sum(~difficult)\n",
    "    class_recs[imagename] = {'bbox': bbox,\n",
    "     #                        'difficult': difficult,\n",
    "                             'det': det}\n",
    "\n",
    "  # read dets\n",
    "  detfile = detpath.format(classname)\n",
    "  with open(detfile, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "  splitlines = [x.strip().split(' ') for x in lines]\n",
    "  image_ids = [x[0] for x in splitlines]\n",
    "  confidence = np.array([float(x[1]) for x in splitlines])\n",
    "  BB = np.array([[float(z) for z in x[2:]] for x in splitlines])\n",
    "\n",
    "  nd = len(image_ids)\n",
    "  tp = np.zeros(nd)\n",
    "  fp = np.zeros(nd)\n",
    "\n",
    "  if BB.shape[0] > 0:\n",
    "    # sort by confidence\n",
    "    sorted_ind = np.argsort(-confidence)\n",
    "    sorted_scores = np.sort(-confidence)\n",
    "    BB = BB[sorted_ind, :]\n",
    "    image_ids = [image_ids[x] for x in sorted_ind]\n",
    "\n",
    "    # go down dets and mark TPs and FPs\n",
    "    for d in range(nd):\n",
    "      R = class_recs[image_ids[d]]\n",
    "      bb = BB[d, :].astype(float)\n",
    "      ovmax = -np.inf\n",
    "      BBGT = R['bbox'].astype(float)\n",
    "\n",
    "      if BBGT.size > 0:\n",
    "        # compute overlaps\n",
    "        # intersection\n",
    "        ixmin = np.maximum(BBGT[:, 0], bb[0])\n",
    "        iymin = np.maximum(BBGT[:, 1], bb[1])\n",
    "        ixmax = np.minimum(BBGT[:, 2], bb[2])\n",
    "        iymax = np.minimum(BBGT[:, 3], bb[3])\n",
    "        iw = np.maximum(ixmax - ixmin + 1., 0.)\n",
    "        ih = np.maximum(iymax - iymin + 1., 0.)\n",
    "        inters = iw * ih\n",
    "\n",
    "        # union\n",
    "        uni = ((bb[2] - bb[0] + 1.) * (bb[3] - bb[1] + 1.) +\n",
    "               (BBGT[:, 2] - BBGT[:, 0] + 1.) *\n",
    "               (BBGT[:, 3] - BBGT[:, 1] + 1.) - inters)\n",
    "\n",
    "        overlaps = inters / uni\n",
    "        ovmax = np.max(overlaps)\n",
    "        jmax = np.argmax(overlaps)\n",
    "\n",
    "      if ovmax > ovthresh:\n",
    "        #if not R['difficult'][jmax]:\n",
    "        if not R['det'][jmax]:\n",
    "          tp[d] = 1.\n",
    "          R['det'][jmax] = 1\n",
    "        else:\n",
    "          fp[d] = 1.\n",
    "      else:\n",
    "        fp[d] = 1.\n",
    "\n",
    "  # compute precision recall\n",
    "  fp = np.cumsum(fp)\n",
    "  tp = np.cumsum(tp)\n",
    "  rec = tp / float(npos)\n",
    "  # avoid divide by zero in case the first detection matches a difficult\n",
    "  # ground truth\n",
    "  prec = tp / np.maximum(tp + fp, np.finfo(np.float64).eps)\n",
    "  ap = voc_ap(rec, prec, use_07_metric)\n",
    "\n",
    "  return rec, prec, ap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdfab81",
   "metadata": {},
   "source": [
    "## bg_num_rois = 0 and fg_num_rois = 0, this should not happen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8072e9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pkl_filepath = 'data/cache/multi_ck_train_gt_roidb.pkl'\n",
    "with open(pkl_filepath, 'rb') as f:\n",
    "    multick_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "71e94e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17898"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(multick_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3999f134",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_filepath = 'data/cache/kitti_train_gt_roidb.pkl'\n",
    "with open(pkl_filepath, 'rb') as f:\n",
    "    kiti_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "da03d97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17952"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kiti_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6675bf5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': array([[414, 143, 512, 307]], dtype=uint16),\n",
       " 'gt_overlaps': <1x3 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 1 stored elements in Compressed Sparse Row format>,\n",
       " 'gt_classes': array([2], dtype=int32),\n",
       " 'flipped': True}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kiti_data[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c6f5ac14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': array([[414, 143, 512, 307]], dtype=uint16),\n",
       " 'gt_overlaps': <1x9 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 1 stored elements in Compressed Sparse Row format>,\n",
       " 'gt_classes': array([2], dtype=int32),\n",
       " 'flipped': True,\n",
       " 'img_id': 11914,\n",
       " 'image': '/home/superorange5/Research/FedWCD/data/KITTI/JPEGImages/000000.png',\n",
       " 'width': 1224,\n",
       " 'height': 370,\n",
       " 'max_classes': array([2]),\n",
       " 'max_overlaps': array([1.], dtype=float32)}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multick_data[11914]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7769df",
   "metadata": {},
   "source": [
    "## roidb rank width error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb129535",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cache_path = 'data/cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83847a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pkl_filepath = 'data/cache/kitti_train_gt_roidb.pkl'\n",
    "with open(pkl_filepath, 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "455eb6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kitti_train\n"
     ]
    }
   ],
   "source": [
    "for s in 'kitti_train'.split('+'):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ebce20",
   "metadata": {},
   "source": [
    "### rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9dd5ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_file = os.path.join(data_cache_path, 'kitti_train_small_gt_roidb.pkl')\n",
    "\n",
    "with open(pkl_file, 'rb') as f:\n",
    "    roidb = pickle.load(f)\n",
    "\n",
    "#roidb = filter_roidb(roidb)\n",
    "train_size = len(roidb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "593827fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "259e4a6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-8f753001ccaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mroidb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m11967\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "roidb[11967]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "551ed53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': array([[414, 143, 512, 307]], dtype=uint16),\n",
       " 'gt_overlaps': <1x3 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 1 stored elements in Compressed Sparse Row format>,\n",
       " 'gt_classes': array([2], dtype=int32),\n",
       " 'flipped': True}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roidb[11968]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a5d4c12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####0\n",
      "#####1\n",
      "#####2\n",
      "#####3\n",
      "#####4\n",
      "#####5\n",
      "#####6\n",
      "#####7\n",
      "#####8\n",
      "#####9\n",
      "#####10\n",
      "#####11\n",
      "#####12\n",
      "#####13\n",
      "#####14\n",
      "#####15\n",
      "#####16\n",
      "#####17\n",
      "#####18\n",
      "#####19\n",
      "#####20\n",
      "#####21\n",
      "#####22\n",
      "#####23\n",
      "#####24\n",
      "#####25\n",
      "#####26\n",
      "#####27\n",
      "#####28\n",
      "#####29\n",
      "#####30\n",
      "#####31\n",
      "#####32\n",
      "#####33\n",
      "#####34\n",
      "#####35\n",
      "#####36\n",
      "#####37\n",
      "#####38\n",
      "#####39\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ratio_large = 2 # largest ratio to preserve.\n",
    "ratio_small = 0.5 # smallest ratio to preserve.    \n",
    "    \n",
    "ratio_list = []\n",
    " #   print(len(roidb))\n",
    "for i in range(len(roidb)):\n",
    "    print('#####'+str(i))\n",
    "      \n",
    "    width = roidb[i]['width']\n",
    "    height = roidb[i]['height']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2ec38bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_roidb(imdb_names, training=True):\n",
    "  \"\"\"\n",
    "  Combine multiple roidbs\n",
    "  \"\"\"\n",
    "\n",
    "  def get_training_roidb(imdb):\n",
    "    \"\"\"Returns a roidb (Region of Interest database) for use in training.\"\"\"\n",
    "    if cfg.TRAIN.USE_FLIPPED:\n",
    "      print('Appending horizontally-flipped training examples...')\n",
    "      imdb.append_flipped_images()\n",
    "      print('done')\n",
    "\n",
    "    print('Preparing training data...')\n",
    "\n",
    "    prepare_roidb(imdb)\n",
    "    #ratio_index = rank_roidb_ratio(imdb)\n",
    "    print('done')\n",
    "\n",
    "    return imdb.roidb\n",
    "  \n",
    "  def get_roidb(imdb_name):\n",
    "    imdb = get_imdb(imdb_name)\n",
    "    print('Loaded dataset `{:s}` for training'.format(imdb.name))\n",
    "    imdb.set_proposal_method(cfg.TRAIN.PROPOSAL_METHOD)\n",
    "    print('Set proposal method: {:s}'.format(cfg.TRAIN.PROPOSAL_METHOD))\n",
    "    roidb = get_training_roidb(imdb)\n",
    "    return roidb\n",
    "\n",
    "  roidbs = [get_roidb(s) for s in imdb_names.split('+')]\n",
    "  roidb = roidbs[0]\n",
    "  if len(roidbs) > 1:\n",
    "    for r in roidbs[1:]:\n",
    "      roidb.extend(r)\n",
    "    tmp = get_imdb(imdb_names.split('+')[1])\n",
    "    imdb = datasets.imdb.imdb(imdb_names, tmp.classes)\n",
    "  else:\n",
    "    imdb = get_imdb(imdb_names)\n",
    "\n",
    "  if training:\n",
    "    roidb = filter_roidb(roidb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7cf1c577",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(kiti_data)):\n",
    "  #    print('#####'+str(i))\n",
    "    width = multick_data[i]['width']\n",
    "    #print(width)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fee7746",
   "metadata": {},
   "source": [
    "## create a new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7baa5980",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_multick = multick_data[0:100]+multick_data[2965:3065]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f0cc2c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_multick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e3c54e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_file = 'data/cache/multi_ck_trainsmall'\n",
    "with open(cache_file, 'wb') as fid:\n",
    "    pickle.dump(new_multick, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522a94c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_info in data:\n",
    "    bboxes = data_info['boxes']\n",
    "    if len(bboxes) <2:\n",
    "        print (data_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "frcnn",
   "language": "python",
   "name": "frcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
