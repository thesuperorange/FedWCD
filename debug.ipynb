{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29a502cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pkl_filepath = 'data/cache/kitti_train_gt_roidb.pkl'\n",
    "with open(pkl_filepath, 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c59c634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11968\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "871e1c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': array([[712, 143, 810, 307]], dtype=uint16),\n",
       " 'gt_classes': array([2], dtype=int32),\n",
       " 'gt_ishard': array([0], dtype=int32),\n",
       " 'gt_overlaps': <1x3 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 1 stored elements in Compressed Sparse Row format>,\n",
       " 'flipped': False,\n",
       " 'seg_areas': array([16335.], dtype=float32),\n",
       " 'img_id': 0,\n",
       " 'image': '/home/superorange5/Research/FedWCD/data/KITTI/JPEGImages/000000.png',\n",
       " 'width': 1224,\n",
       " 'height': 370,\n",
       " 'max_classes': array([2]),\n",
       " 'max_overlaps': array([1.], dtype=float32)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52073f09",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-73ddaa7b0f37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "data[0].size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1187884d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for datainfo in data:\n",
    "    wh_pair =[(1242,375),(1224,370),(1238,374),(1241,376)]\n",
    "\n",
    "    width = datainfo['width']\n",
    "    height = datainfo['height']\n",
    "    temp = (width,height)\n",
    "    if (temp not in wh_pair):\n",
    "        print(datainfo['image'])\n",
    "        print (width)\n",
    "        print (height)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdd1fd4",
   "metadata": {},
   "source": [
    "## voc_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d6ab365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_cache_path = 'data/cache'\n",
    "pkl_file = os.path.join(data_cache_path, 'bdd100k_val' + '_gt_roidb.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0812c83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pkl_file, 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4afc00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "devkit_path = '/work/superorange5/bdd100k'\n",
    "cachedir = os.path.join(devkit_path, 'annotations_cache')\n",
    "image_set='val'\n",
    "imagesetfile = os.path.join(devkit_path,  'ImageSets',\n",
    "            'Main',   image_set + '.txt')\n",
    "cachefile = os.path.join(cachedir, '%s_annots.pkl' % imagesetfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4f02d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "annopath = os.path.join(devkit_path, 'Annotations', '{:s}.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "288dce67",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(imagesetfile, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "imagenames = [x.strip() for x in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ceffac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/work/superorange5/bdd100k/ImageSets/Main/val.txt_annots.pkl'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cachefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "204ba204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imagenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39aec1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.datasets.voc_eval as voc_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20cc884",
   "metadata": {},
   "source": [
    "## generate gt pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "008d70d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving cached annotations to /work/superorange5/bdd100k/ImageSets/Main/val.txt_annots.pkl\n"
     ]
    }
   ],
   "source": [
    "recs = {}\n",
    "#for i in range(1000):\n",
    "#    imagename = imagenames[i]\n",
    "for i, imagename in enumerate(imagenames):\n",
    "    recs[imagename] = voc_eval.parse_rec(annopath.format(imagename))\n",
    "    if i % 100 == 0:\n",
    "        print('Reading annotation for {:d}/{:d}'.format(\n",
    "          i + 1, len(imagenames)))\n",
    "print('Saving cached annotations to {:s}'.format(cachefile))\n",
    "with open(cachefile, 'wb') as f:\n",
    "        pickle.dump(recs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf980afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'traffic light', 'truncated': 0, 'bbox': [449, 123, 471, 146]},\n",
       " {'name': 'traffic sign', 'truncated': 0, 'bbox': [638, 206, 653, 231]},\n",
       " {'name': 'traffic sign', 'truncated': 0, 'bbox': [199, 179, 231, 212]},\n",
       " {'name': 'car', 'truncated': 0, 'bbox': [439, 222, 698, 430]},\n",
       " {'name': 'car', 'truncated': 1, 'bbox': [1136, 200, 1278, 333]},\n",
       " {'name': 'motor', 'truncated': 1, 'bbox': [1204, 232, 1277, 330]}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs['b1ca8418-84a133a0']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3ba9a3",
   "metadata": {},
   "source": [
    "## extract gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e1c6d061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "classname = 'car' \n",
    "class_recs = {}\n",
    "npos = 0\n",
    "ovthresh=0.5\n",
    "for imagename in imagenames:\n",
    "    R = [obj for obj in recs[imagename] if obj['name'] == classname]\n",
    "    bbox = np.array([x['bbox'] for x in R])\n",
    "    #difficult = np.array([x['difficult'] for x in R]).astype(np.bool)\n",
    "    det = [False] * len(R)\n",
    "    npos = npos +  len(R) #sum(~difficult)\n",
    "    class_recs[imagename] = {'bbox': bbox,\n",
    "     #                        'difficult': difficult,\n",
    "                             'det': det}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d059a8",
   "metadata": {},
   "source": [
    "## read dets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "30ae7ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "detfile = os.path.join(devkit_path,'results/Main/comp4_det_val_'+classname+'.txt')\n",
    "with open(detfile, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "splitlines = [x.strip().split(' ') for x in lines]\n",
    "image_ids = [x[0] for x in splitlines]\n",
    "confidence = np.array([float(x[1]) for x in splitlines])\n",
    "BB = np.array([[float(z) for z in x[2:]] for x in splitlines])\n",
    "\n",
    "nd = len(image_ids)\n",
    "tp = np.zeros(nd)\n",
    "fp = np.zeros(nd)\n",
    "\n",
    "if BB.shape[0] > 0:\n",
    "    # sort by confidence\n",
    "    sorted_ind = np.argsort(-confidence)\n",
    "    sorted_scores = np.sort(-confidence)\n",
    "    BB = BB[sorted_ind, :]\n",
    "    image_ids = [image_ids[x] for x in sorted_ind]\n",
    "\n",
    "    # go down dets and mark TPs and FPs\n",
    "    for d in range(nd):\n",
    "        R = class_recs[image_ids[d]]\n",
    "        bb = BB[d, :].astype(float)\n",
    "        ovmax = -np.inf\n",
    "        BBGT = R['bbox'].astype(float)\n",
    "\n",
    "        if BBGT.size > 0:\n",
    "        # compute overlaps\n",
    "        # intersection\n",
    "            ixmin = np.maximum(BBGT[:, 0], bb[0])\n",
    "            iymin = np.maximum(BBGT[:, 1], bb[1])\n",
    "            ixmax = np.minimum(BBGT[:, 2], bb[2])\n",
    "            iymax = np.minimum(BBGT[:, 3], bb[3])\n",
    "            iw = np.maximum(ixmax - ixmin + 1., 0.)\n",
    "            ih = np.maximum(iymax - iymin + 1., 0.)\n",
    "            inters = iw * ih\n",
    "\n",
    "            # union\n",
    "            uni = ((bb[2] - bb[0] + 1.) * (bb[3] - bb[1] + 1.) +\n",
    "                   (BBGT[:, 2] - BBGT[:, 0] + 1.) *\n",
    "                   (BBGT[:, 3] - BBGT[:, 1] + 1.) - inters)\n",
    "\n",
    "            overlaps = inters / uni\n",
    "            ovmax = np.max(overlaps)\n",
    "            jmax = np.argmax(overlaps)\n",
    "\n",
    "        if ovmax > ovthresh:\n",
    "        #if not R['difficult'][jmax]:\n",
    "            if not R['det'][jmax]:\n",
    "                tp[d] = 1.\n",
    "                R['det'][jmax] = 1\n",
    "            else:\n",
    "                fp[d] = 1.\n",
    "        else:\n",
    "            fp[d] = 1.\n",
    "\n",
    "  # compute precision recall\n",
    "fp = np.cumsum(fp)\n",
    "tp = np.cumsum(tp)\n",
    "rec = tp / float(npos)\n",
    "  # avoid divide by zero in case the first detection matches a difficult\n",
    "  # ground truth\n",
    "prec = tp / np.maximum(tp + fp, np.finfo(np.float64).eps)\n",
    "ap = voc_eval.voc_ap(rec, prec, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "970f0156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2416113877975409"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9af175c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(cachefile):\n",
    "    # load annotations\n",
    "    recs = {}\n",
    "    for i, imagename in enumerate(imagenames):\n",
    "      recs[imagename] = parse_rec(annopath.format(imagename))\n",
    "      if i % 10 == 0:\n",
    "        print('Reading annotation for {:d}/{:d}'.format(\n",
    "          i + 1, len(imagenames)))\n",
    "    # save\n",
    "    print('Saving cached annotations to {:s}'.format(cachefile))\n",
    "    with open(cachefile, 'wb') as f:\n",
    "      pickle.dump(recs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0917c30b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': array([[1001,  282, 1041,  327],\n",
       "        [ 215,  172,  275,  230],\n",
       "        [ 797,  313,  830,  342],\n",
       "        [ 653,  303,  685,  316],\n",
       "        [ 707,  312,  716,  328],\n",
       "        [ 626,  296,  636,  317],\n",
       "        [ 317,  289,  329,  307],\n",
       "        [ 271,  288,  309,  302],\n",
       "        [ 221,  301,  232,  312],\n",
       "        [ 206,  338,  282,  388],\n",
       "        [  47,  344,  130,  401],\n",
       "        [ 247,  344,  347,  396],\n",
       "        [   0,  337,   52,  403],\n",
       "        [ 650,  354,  664,  382],\n",
       "        [ 649,  367,  664,  388],\n",
       "        [ 712,  337,  726,  353],\n",
       "        [ 684,  357,  721,  393],\n",
       "        [ 706,  364,  734,  391],\n",
       "        [ 727,  366,  761,  401],\n",
       "        [ 749,  362,  809,  409],\n",
       "        [ 787,  358,  906,  425],\n",
       "        [ 880,  376,  960,  452],\n",
       "        [ 936,  336, 1212,  484],\n",
       "        [1204,  416, 1279,  530],\n",
       "        [ 603,  341,  610,  353],\n",
       "        [ 591,  328,  598,  342],\n",
       "        [ 529,  332,  537,  342],\n",
       "        [ 552,  356,  565,  368],\n",
       "        [ 574,  352,  586,  369],\n",
       "        [ 581,  357,  598,  378],\n",
       "        [ 596,  352,  636,  386],\n",
       "        [ 518,  356,  535,  368],\n",
       "        [ 502,  357,  518,  371],\n",
       "        [ 453,  353,  479,  373]], dtype=uint16),\n",
       " 'gt_classes': array([9, 9, 9, 9, 8, 8, 8, 9, 9, 1, 1, 1, 1, 3, 7, 8, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1], dtype=int32),\n",
       " 'gt_ishard': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " 'gt_overlaps': <34x11 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 34 stored elements in Compressed Sparse Row format>,\n",
       " 'flipped': False,\n",
       " 'seg_areas': array([ 1886.,  3599.,  1020.,   462.,   170.,   242.,   247.,   585.,\n",
       "          144.,  3927.,  4872.,  5353.,  3551.,   435.,   352.,   255.,\n",
       "         1406.,   812.,  1260.,  2928.,  8160.,  6237., 41273.,  8740.,\n",
       "          104.,   120.,    99.,   182.,   234.,   396.,  1435.,   234.,\n",
       "          255.,   567.], dtype=float32),\n",
       " 'img_id': 0,\n",
       " 'image': '/home/superorange5/Research/FedWCD/data/BDD100K/JPEGImages/b1c66a42-6f7d68ca.jpg',\n",
       " 'width': 1280,\n",
       " 'height': 720,\n",
       " 'max_classes': array([9, 9, 9, 9, 8, 8, 8, 9, 9, 1, 1, 1, 1, 3, 7, 8, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 'max_overlaps': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "  cachefile = os.path.join(cachedir, '%s_annots.pkl' % imagesetfile)\n",
    "  # read list of images\n",
    "  with open(imagesetfile, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "  imagenames = [x.strip() for x in lines]\n",
    "\n",
    "  if not os.path.isfile(cachefile):\n",
    "    # load annotations\n",
    "    recs = {}\n",
    "    for i, imagename in enumerate(imagenames):\n",
    "      recs[imagename] = parse_rec(annopath.format(imagename))\n",
    "      if i % 100 == 0:\n",
    "        print('Reading annotation for {:d}/{:d}'.format(\n",
    "          i + 1, len(imagenames)))\n",
    "    # save\n",
    "    print('Saving cached annotations to {:s}'.format(cachefile))\n",
    "    with open(cachefile, 'wb') as f:\n",
    "      pickle.dump(recs, f)\n",
    "  else:\n",
    "    # load\n",
    "    with open(cachefile, 'rb') as f:\n",
    "      try:\n",
    "        recs = pickle.load(f)\n",
    "      except:\n",
    "        recs = pickle.load(f, encoding='bytes')\n",
    "\n",
    "  # extract gt objects for this class\n",
    "  class_recs = {}\n",
    "  npos = 0\n",
    "  for imagename in imagenames:\n",
    "    R = [obj for obj in recs[imagename] if obj['name'] == classname]\n",
    "    bbox = np.array([x['bbox'] for x in R])\n",
    "    #difficult = np.array([x['difficult'] for x in R]).astype(np.bool)\n",
    "    det = [False] * len(R)\n",
    "    #npos = npos + sum(~difficult)\n",
    "    class_recs[imagename] = {'bbox': bbox,\n",
    "     #                        'difficult': difficult,\n",
    "                             'det': det}\n",
    "\n",
    "  # read dets\n",
    "  detfile = detpath.format(classname)\n",
    "  with open(detfile, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "  splitlines = [x.strip().split(' ') for x in lines]\n",
    "  image_ids = [x[0] for x in splitlines]\n",
    "  confidence = np.array([float(x[1]) for x in splitlines])\n",
    "  BB = np.array([[float(z) for z in x[2:]] for x in splitlines])\n",
    "\n",
    "  nd = len(image_ids)\n",
    "  tp = np.zeros(nd)\n",
    "  fp = np.zeros(nd)\n",
    "\n",
    "  if BB.shape[0] > 0:\n",
    "    # sort by confidence\n",
    "    sorted_ind = np.argsort(-confidence)\n",
    "    sorted_scores = np.sort(-confidence)\n",
    "    BB = BB[sorted_ind, :]\n",
    "    image_ids = [image_ids[x] for x in sorted_ind]\n",
    "\n",
    "    # go down dets and mark TPs and FPs\n",
    "    for d in range(nd):\n",
    "      R = class_recs[image_ids[d]]\n",
    "      bb = BB[d, :].astype(float)\n",
    "      ovmax = -np.inf\n",
    "      BBGT = R['bbox'].astype(float)\n",
    "\n",
    "      if BBGT.size > 0:\n",
    "        # compute overlaps\n",
    "        # intersection\n",
    "        ixmin = np.maximum(BBGT[:, 0], bb[0])\n",
    "        iymin = np.maximum(BBGT[:, 1], bb[1])\n",
    "        ixmax = np.minimum(BBGT[:, 2], bb[2])\n",
    "        iymax = np.minimum(BBGT[:, 3], bb[3])\n",
    "        iw = np.maximum(ixmax - ixmin + 1., 0.)\n",
    "        ih = np.maximum(iymax - iymin + 1., 0.)\n",
    "        inters = iw * ih\n",
    "\n",
    "        # union\n",
    "        uni = ((bb[2] - bb[0] + 1.) * (bb[3] - bb[1] + 1.) +\n",
    "               (BBGT[:, 2] - BBGT[:, 0] + 1.) *\n",
    "               (BBGT[:, 3] - BBGT[:, 1] + 1.) - inters)\n",
    "\n",
    "        overlaps = inters / uni\n",
    "        ovmax = np.max(overlaps)\n",
    "        jmax = np.argmax(overlaps)\n",
    "\n",
    "      if ovmax > ovthresh:\n",
    "        #if not R['difficult'][jmax]:\n",
    "        if not R['det'][jmax]:\n",
    "          tp[d] = 1.\n",
    "          R['det'][jmax] = 1\n",
    "        else:\n",
    "          fp[d] = 1.\n",
    "      else:\n",
    "        fp[d] = 1.\n",
    "\n",
    "  # compute precision recall\n",
    "  fp = np.cumsum(fp)\n",
    "  tp = np.cumsum(tp)\n",
    "  rec = tp / float(npos)\n",
    "  # avoid divide by zero in case the first detection matches a difficult\n",
    "  # ground truth\n",
    "  prec = tp / np.maximum(tp + fp, np.finfo(np.float64).eps)\n",
    "  ap = voc_ap(rec, prec, use_07_metric)\n",
    "\n",
    "  return rec, prec, ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95373014",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "frcnn",
   "language": "python",
   "name": "frcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
