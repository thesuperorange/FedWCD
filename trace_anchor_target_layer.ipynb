{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _init_paths\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import pickle\n",
    "from roi_data_layer.roidb import combined_roidb, rank_roidb_ratio, filter_roidb\n",
    "from roi_data_layer.roibatchLoader import roibatchLoader\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load gt box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cache_path = 'data/cache'\n",
    "imdb_classes =  ('__background__',  # always index 0\n",
    "                          'person',\n",
    "                          'people','cyclist'\n",
    "                         )\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sampler(Sampler):\n",
    "    def __init__(self, train_size, batch_size):\n",
    "        self.num_data = train_size\n",
    "        self.num_per_batch = int(train_size / batch_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.range = torch.arange(0, batch_size).view(1, batch_size).long()\n",
    "        self.leftover_flag = False\n",
    "        if train_size % batch_size:\n",
    "            self.leftover = torch.arange(self.num_per_batch * batch_size, train_size).long()\n",
    "            self.leftover_flag = True\n",
    "\n",
    "    def __iter__(self):\n",
    "        rand_num = torch.randperm(self.num_per_batch).view(-1, 1) * self.batch_size\n",
    "        self.rand_num = rand_num.expand(self.num_per_batch, self.batch_size) + self.range\n",
    "\n",
    "        self.rand_num_view = self.rand_num.view(-1)\n",
    "\n",
    "        if self.leftover_flag:\n",
    "            self.rand_num_view = torch.cat((self.rand_num_view, self.leftover), 0)\n",
    "\n",
    "        return iter(self.rand_num_view)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_client_dataset(imdb_name):\n",
    "    #dataloader_list = []\n",
    "    #iter_epochs_list = []\n",
    "    #for imdb_name in imdb_list:\n",
    "    pkl_file = os.path.join(data_cache_path, imdb_name + '_gt_roidb.pkl')\n",
    "\n",
    "    with open(pkl_file, 'rb') as f:\n",
    "        roidb = pickle.load(f)\n",
    "\n",
    "    roidb = filter_roidb(roidb)\n",
    "\n",
    "    ratio_list, ratio_index = rank_roidb_ratio(roidb)\n",
    "\n",
    "    train_size = len(roidb)\n",
    "    print(train_size)\n",
    "    iters_per_epoch = int(train_size / args.batch_size)\n",
    "    print('iters_per_epoch: ' + str(iters_per_epoch))\n",
    "    #iter_epochs_list.append(iters_per_epoch)\n",
    "    sampler_batch = sampler(train_size, args.batch_size)\n",
    "\n",
    "    dataset = roibatchLoader(roidb, ratio_list, ratio_index, args.batch_size, imdb_classes, training=True)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=args.batch_size,\n",
    "                                             sampler=sampler_batch, num_workers=args.num_workers)\n",
    "    #dataloader_list.append(dataloader)\n",
    "    return dataloader,iters_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        self.class_agnostic =False\n",
    "        self.epochs = 3\n",
    "        self.lr = 0.001\n",
    "        self.lr_decay_step = 4\n",
    "        self.dataset = 'KAIST'\n",
    "        self.net = 'vgg16'\n",
    "        self.batch_size = 24\n",
    "        \n",
    "        self.cuda = True\n",
    "        #self.round = 10\n",
    "        self.mGPUs=True\n",
    "        self.optimizer =\"sgd\"\n",
    "        self.k=3\n",
    "        self.num_workers = 2\n",
    "        #self.device = th.device(\"cpu\")\n",
    "        \n",
    "args = Arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before filtering, there are 43244 images...\n",
      "after filtering, there are 43244 images...\n",
      "43244\n",
      "iters_per_epoch: 1801\n"
     ]
    }
   ],
   "source": [
    "imdb_name = 'KAIST_train'\n",
    "dataloader,iters_per_epoch  = load_client_dataset(imdb_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(dataloader)\n",
    "data = next(data_iter)\n",
    "im_data = torch.FloatTensor(1)\n",
    "im_info = torch.FloatTensor(1)\n",
    "num_boxes = torch.LongTensor(1)\n",
    "gt_boxes = torch.FloatTensor(1)\n",
    "\n",
    "# ship to cuda\n",
    "\n",
    "im_data = im_data.to(device)\n",
    "im_info = im_info.to(device)\n",
    "num_boxes = num_boxes.to(device)\n",
    "gt_boxes = gt_boxes.to(device)\n",
    "\n",
    "# make variable\n",
    "im_data = Variable(im_data)\n",
    "im_info = Variable(im_info)\n",
    "num_boxes = Variable(num_boxes)\n",
    "gt_boxes = Variable(gt_boxes)\n",
    "\n",
    "with torch.no_grad():\n",
    "    im_data.resize_(data[0].size()).copy_(data[0])\n",
    "    im_info.resize_(data[1].size()).copy_(data[1])\n",
    "    gt_boxes.resize_(data[2].size()).copy_(data[2])\n",
    "    num_boxes.resize_(data[3].size()).copy_(data[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -38.,  -16.,   53.,   31.],\n",
      "        [ -84.,  -40.,   99.,   55.],\n",
      "        [-176.,  -88.,  191.,  103.],\n",
      "        [-360., -184.,  375.,  199.],\n",
      "        [ -24.,  -24.,   39.,   39.],\n",
      "        [ -56.,  -56.,   71.,   71.],\n",
      "        [-120., -120.,  135.,  135.],\n",
      "        [-248., -248.,  263.,  263.],\n",
      "        [ -14.,  -36.,   29.,   51.],\n",
      "        [ -36.,  -80.,   51.,   95.],\n",
      "        [ -80., -168.,   95.,  183.],\n",
      "        [-168., -344.,  183.,  359.]])\n",
      "torch.Size([12, 4])\n"
     ]
    }
   ],
   "source": [
    "from lib.model.rpn.generate_anchors import generate_anchors\n",
    "anchor_scales= [4,8,16,32]\n",
    "\n",
    "# Anchor ratios for RPN\n",
    "ratios = [0.5,1,2]\n",
    "_anchors = torch.from_numpy(generate_anchors(scales=np.array(anchor_scales), ratios=np.array(ratios))).float()\n",
    "print(_anchors)\n",
    "print(_anchors.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_height, feat_width = 37,46\n",
    "_feat_stride=16\n",
    "shift_x = np.arange(0, feat_width) * _feat_stride\n",
    "shift_y = np.arange(0, feat_height) * _feat_stride\n",
    "shift_x, shift_y = np.meshgrid(shift_x, shift_y)\n",
    "shifts = torch.from_numpy(np.vstack((shift_x.ravel(), shift_y.ravel(),\n",
    "                          shift_x.ravel(), shift_y.ravel())).transpose())\n",
    "shifts = shifts.contiguous().type(torch.cuda.FloatTensor).float()\n",
    "                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1702, 4])\n",
      "tensor([[  0.,   0.,   0.,   0.],\n",
      "        [ 16.,   0.,  16.,   0.],\n",
      "        [ 32.,   0.,  32.,   0.],\n",
      "        ...,\n",
      "        [688., 576., 688., 576.],\n",
      "        [704., 576., 704., 576.],\n",
      "        [720., 576., 720., 576.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(shifts.size())\n",
    "print(shifts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1702\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "K = shifts.size(0)\n",
    "A = _anchors.size(0)\n",
    "print(K)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1702, 12, 4])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(_anchors.view(1, A, 4) + shifts.view(K, 1, 4)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20424"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_anchors = _anchors.type(torch.cuda.FloatTensor) # move to specific gpu.\n",
    "all_anchors = _anchors.view(1, A, 4) + shifts.view(K, 1, 4)\n",
    "all_anchors = all_anchors.view(K * A, 4)\n",
    "\n",
    "total_anchors = int(K * A)\n",
    "total_anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  588],\n",
       "        [  600],\n",
       "        [  612],\n",
       "        ...,\n",
       "        [19836],\n",
       "        [19840],\n",
       "        [19852]], device='cuda:0')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_allowed_border = 0  \n",
    "try:\n",
    "    long        # Python 2\n",
    "except NameError:\n",
    "    long = int  # Python 3\n",
    "keep = ((all_anchors[:, 0] >= -_allowed_border) &\n",
    "                (all_anchors[:, 1] >= -_allowed_border) &\n",
    "                (all_anchors[:, 2] < 750 + _allowed_border) &\n",
    "                (all_anchors[:, 3] < 600 + _allowed_border))\n",
    "\n",
    "torch.nonzero(keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  588],\n",
      "        [  600],\n",
      "        [  612],\n",
      "        ...,\n",
      "        [19836],\n",
      "        [19840],\n",
      "        [19852]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch.nonzero(keep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1, device='cuda:0', dtype=torch.uint8)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep[19852]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  588,   600,   612,  ..., 19836, 19840, 19852], device='cuda:0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inds_inside = torch.nonzero(keep).view(-1)\n",
    "inds_inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.model.rpn.bbox_transform import clip_boxes, bbox_overlaps_batch, bbox_transform_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds_inside = torch.nonzero(keep).view(-1)\n",
    "\n",
    "# keep only inside anchors\n",
    "anchors = all_anchors[inds_inside, :]\n",
    "batch_size=args.batch_size\n",
    "# label: 1 is positive, 0 is negative, -1 is dont care\n",
    "labels = gt_boxes.new(batch_size, inds_inside.size(0)).fill_(-1)  #[24, 9720]\n",
    "bbox_inside_weights = gt_boxes.new(batch_size, inds_inside.size(0)).zero_()\n",
    "bbox_outside_weights = gt_boxes.new(batch_size, inds_inside.size(0)).zero_()\n",
    "\n",
    "overlaps = bbox_overlaps_batch(anchors, gt_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 9720, 20])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlaps.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0, 1415,    4],\n",
       "        [   0, 1423,    0],\n",
       "        [   0, 1423,    2],\n",
       "        ...,\n",
       "        [  23, 7585,    0],\n",
       "        [  23, 7590,    0],\n",
       "        [  23, 7598,    0]], device='cuda:0')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(overlaps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0034, device='cuda:0')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlaps[0][1415][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0, 1415],\n",
       "        [   0, 1423],\n",
       "        [   0, 1431],\n",
       "        ...,\n",
       "        [  20, 7816],\n",
       "        [  20, 7824],\n",
       "        [  20, 7832]], device='cuda:0')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(argmax_overlaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4, device='cuda:0')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argmax_overlaps[0][1415]  #記錄與anchor overlap最大的gt index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0034, device='cuda:0')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_overlaps[0][1415]#記錄與anchor overlap最大的ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7047, 0.5380, 0.3465, 0.5194, 0.3391, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [0.6389, 0.3169, 0.5897, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [0.3835, 0.4471, 0.3838, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [0.5221, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [0.5337, 0.5013, 0.5452, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [0.5946, 0.4905, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [0.3465, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [0.5616, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [0.6312, 0.5387, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [0.7468, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [0.5351, 0.7148, 0.7960, 0.5995, 0.7642, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [0.4122, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [0.5089, 0.4600, 0.8279, 0.8093, 0.7725, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [0.6333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [0.6487, 0.6530, 0.7014, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [0.7258, 0.4810, 0.4932, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [0.6680, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [0.6457, 0.7089, 0.7458, 0.4982, 0.5686, 0.7062, 0.6076, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [0.3334, 0.5947, 0.3370, 0.3400, 0.5580, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [0.5763, 0.1954, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [0.4174, 0.2980, 0.2143, 0.3400, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [0.6480, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [0.7147, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [0.4413, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_overlaps, argmax_overlaps = torch.max(overlaps, 2)\n",
    "gt_max_overlaps, _ = torch.max(overlaps, 1)\n",
    "#max_overlaps.size()  #torch.Size([24, 9720])\n",
    "#argmax_overlaps 24, 9720\n",
    "gt_max_overlaps #[24,20] #gt找最大的overlap ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2686, 2])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filter <0.3\n",
    "RPN_NEGATIVE_OVERLAP=0.3\n",
    "labels[max_overlaps < RPN_NEGATIVE_OVERLAP] = 0  #[24,9720] anchor數\n",
    "torch.nonzero(labels).size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0, 3764],\n",
       "        [   0, 4097],\n",
       "        [   0, 4106],\n",
       "        ...,\n",
       "        [  23, 4460],\n",
       "        [  23, 4799],\n",
       "        [  23, 4808]], device='cuda:0')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0, 4097,    4],\n",
      "        [   0, 4106,    2],\n",
      "        [   0, 4448,    4],\n",
      "        [   0, 4457,    2],\n",
      "        [   0, 4817,    0],\n",
      "        [   0, 4896,    1],\n",
      "        [   0, 4900,    3],\n",
      "        [   0, 5247,    1],\n",
      "        [   0, 5251,    3],\n",
      "        [   0, 5598,    1],\n",
      "        [   0, 5602,    3],\n",
      "        [   0, 5953,    3],\n",
      "        [   1, 3996,    1],\n",
      "        [   1, 4347,    1],\n",
      "        [   1, 6249,    2],\n",
      "        [   1, 6277,    0],\n",
      "        [   1, 6585,    2],\n",
      "        [   1, 6613,    0],\n",
      "        [   1, 6921,    2],\n",
      "        [   1, 7257,    2],\n",
      "        [   1, 7592,    2],\n",
      "        [   2, 3966,    2],\n",
      "        [   2, 4317,    2],\n",
      "        [   2, 4484,    1],\n",
      "        [   2, 4500,    0],\n",
      "        [   2, 4668,    2],\n",
      "        [   2, 4835,    1],\n",
      "        [   2, 4851,    0],\n",
      "        [   3, 4466,    0],\n",
      "        [   4, 4508,    2],\n",
      "        [   4, 4536,    1],\n",
      "        [   4, 4874,    0],\n",
      "        [   5, 2885,    1],\n",
      "        [   5, 3184,    0],\n",
      "        [   5, 3221,    1],\n",
      "        [   6, 4448,    0],\n",
      "        [   6, 4799,    0],\n",
      "        [   7, 4190,    0],\n",
      "        [   8, 4253,    1],\n",
      "        [   8, 4604,    1],\n",
      "        [   8, 4630,    0],\n",
      "        [   8, 4955,    1],\n",
      "        [   8, 4981,    0],\n",
      "        [   9, 4572,    0],\n",
      "        [  10, 4411,    3],\n",
      "        [  10, 4421,    3],\n",
      "        [  10, 4431,    3],\n",
      "        [  10, 5168,    0],\n",
      "        [  10, 5225,    1],\n",
      "        [  10, 5519,    0],\n",
      "        [  10, 5870,    0],\n",
      "        [  10, 6126,    4],\n",
      "        [  10, 6569,    2],\n",
      "        [  11, 4252,    0],\n",
      "        [  11, 4603,    0],\n",
      "        [  12, 4081,    1],\n",
      "        [  12, 4091,    1],\n",
      "        [  12, 4101,    1],\n",
      "        [  12, 4110,    1],\n",
      "        [  12, 4119,    1],\n",
      "        [  12, 4128,    1],\n",
      "        [  12, 4137,    1],\n",
      "        [  12, 4145,    1],\n",
      "        [  12, 4432,    1],\n",
      "        [  12, 4442,    1],\n",
      "        [  12, 4452,    1],\n",
      "        [  12, 4461,    1],\n",
      "        [  12, 4470,    1],\n",
      "        [  12, 4479,    1],\n",
      "        [  12, 4488,    1],\n",
      "        [  12, 4496,    1],\n",
      "        [  12, 5039,    0],\n",
      "        [  12, 5390,    0],\n",
      "        [  12, 5712,    4],\n",
      "        [  12, 6371,    3],\n",
      "        [  12, 6415,    2],\n",
      "        [  13, 4689,    0],\n",
      "        [  13, 5040,    0],\n",
      "        [  13, 5391,    0],\n",
      "        [  14, 5519,    1],\n",
      "        [  14, 5537,    2],\n",
      "        [  14, 5545,    0],\n",
      "        [  15, 4541,    1],\n",
      "        [  15, 4545,    2],\n",
      "        [  15, 4587,    0],\n",
      "        [  16, 4204,    0],\n",
      "        [  17, 4327,    0],\n",
      "        [  17, 4347,    5],\n",
      "        [  17, 4541,    3],\n",
      "        [  17, 4887,    1],\n",
      "        [  17, 4892,    3],\n",
      "        [  17, 5657,    2],\n",
      "        [  17, 5666,    2],\n",
      "        [  17, 6762,    4],\n",
      "        [  17, 6771,    4],\n",
      "        [  17, 6780,    4],\n",
      "        [  17, 7098,    4],\n",
      "        [  17, 7107,    4],\n",
      "        [  17, 7116,    4],\n",
      "        [  17, 7315,    6],\n",
      "        [  17, 7434,    4],\n",
      "        [  17, 7443,    4],\n",
      "        [  17, 7452,    4],\n",
      "        [  18, 4149,    2],\n",
      "        [  18, 4157,    3],\n",
      "        [  18, 4165,    0],\n",
      "        [  18, 4165,    3],\n",
      "        [  18, 4172,    0],\n",
      "        [  18, 4500,    2],\n",
      "        [  18, 4508,    3],\n",
      "        [  18, 4516,    0],\n",
      "        [  18, 4516,    3],\n",
      "        [  18, 4523,    0],\n",
      "        [  18, 4530,    4],\n",
      "        [  18, 4541,    1],\n",
      "        [  19, 3610,    1],\n",
      "        [  19, 3946,    1],\n",
      "        [  19, 4297,    1],\n",
      "        [  19, 4896,    0],\n",
      "        [  20, 3928,    2],\n",
      "        [  20, 4279,    2],\n",
      "        [  20, 4337,    0],\n",
      "        [  20, 4337,    1],\n",
      "        [  20, 4347,    1],\n",
      "        [  20, 4347,    3],\n",
      "        [  20, 4357,    3],\n",
      "        [  20, 4630,    2],\n",
      "        [  20, 4688,    0],\n",
      "        [  20, 4688,    1],\n",
      "        [  20, 4698,    1],\n",
      "        [  20, 4698,    3],\n",
      "        [  20, 4708,    3],\n",
      "        [  21, 4357,    0],\n",
      "        [  22, 5238,    0],\n",
      "        [  23, 4097,    0],\n",
      "        [  23, 4448,    0]], device='cuda:0')\n",
      "tensor(1, device='cuda:0', dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "temp_a = overlaps.eq(gt_max_overlaps.view(batch_size,1,-1).expand_as(overlaps))\n",
    "print(torch.nonzero(temp_a))\n",
    "print(temp_a[10][4411][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1, device='cuda:0')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_max_overlaps[gt_max_overlaps==0] = 1e-5\n",
    "keep = torch.sum(overlaps.eq(gt_max_overlaps.view(batch_size,1,-1).expand_as(overlaps)), 2)\n",
    "#keep.size() #24,9720\n",
    "torch.nonzero(keep)\n",
    "keep[0][4097]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.sum(keep) > 0:\n",
    "    labels[keep>0] = 1\n",
    "    \n",
    "RPN_POSITIVE_OVERLAP=0.7\n",
    "# fg label: above threshold IOU\n",
    "labels[max_overlaps >= RPN_POSITIVE_OVERLAP] = 1\n",
    "\n",
    "\n",
    "\n",
    "num_fg = int(0.5 * 256)\n",
    "\n",
    "sum_fg = torch.sum((labels == 1).int(), 1)\n",
    "sum_bg = torch.sum((labels == 0).int(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 9720])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12,  9,  7,  1,  3,  3,  2,  1,  5,  1, 15,  2, 25,  3,  3,  3,  1, 19,\n",
       "        10,  4,  9,  1,  2,  2], device='cuda:0')"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum((labels == 1).int(), 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fasterRCNN",
   "language": "python",
   "name": "fasterrcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
